# -*- coding: utf-8 -*-
"""st.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TZPGxl8soQReZ3bNsI0XTL1bKjJEW2Qt
"""

import streamlit as st
from datetime import date
import pandas as pd
import requests
from bs4 import BeautifulSoup
import webbrowser
from plyer import notification

class MonApp:
    def __init__(self):
        st.title("Nouvelle recherche")

        self.df = pd.DataFrame()
        self.df2 = pd.DataFrame()
        self.df_ct = pd.DataFrame()

        self.prix_min = st.text_input("Prix Min:")
        self.prix_max = st.text_input("Prix Max:")
        self.km_min = st.text_input("Kilométrage Min:")
        self.km_max = st.text_input("Kilométrage Max:")
        self.annee_min = st.text_input("Année Min:")
        self.annee_max = st.text_input("Année Max:")

        list_carburant = ["Diesel", "Essence", "Hybride", "Electrique", "Gaz", "Hydrogene"]
        carburant = st.selectbox("Carburant:", list_carburant)

        list_type = ["Berlines", "Breaks", "4x4-suv", "Citadines", "Monospaces", "Coupé", "Cabriolets"]
        type_vehicule = st.selectbox("Type:", list_type)

        if st.button("OK"):
            self.url_argus, self.url_ct = self.build_urls(type_vehicule, carburant)
            self.recherche_periodique()

    def build_urls(self, type_vehicule, carburant):
        base_url_argus = "https://occasion.largus.fr/auto/"
        base_url_ct = "https://www.lacentrale.fr/listing"

        url_argus = f"{base_url_argus}?category={type_vehicule.lower()}&energy={carburant.lower()}"
        url_ct = f"{base_url_ct}?categories=44&energies={carburant.lower()[:4]}"

        for param, value in [("priceMin", self.prix_min), ("priceMax", self.prix_max),
                             ("mileageMin", self.km_min), ("mileageMax", self.km_max),
                             ("yearMin", self.annee_min), ("yearMax", self.annee_max)]:
            if value:
                url_argus += f"&{param}={value}"
                url_ct += f"&{param}={value}"

        return url_argus, url_ct

    def recherche_periodique(self):

        self.scraping(self.url_argus, self.url_ct)

    def imprimer_ligne_selectionnee(self):
        # Imprime les valeurs de la ligne sélectionnée
        item = st.session_state.selected_item
        if item:
            link_value = self.df2.loc[item, "url"]
            # Ouvre le lien dans un navigateur web externe
            webbrowser.open(link_value)

    def scraping(self, lien1, lien2):
        headers = {
            "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-language": "fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7",
            "Cache-control": "max-age=0",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-User": "?1",
            "user-agent": "Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36"
        }

        response = requests.get(lien1, headers=headers)
        htmlpage2 = BeautifulSoup(response.text, "html.parser")
        url = []
        Model = []
        Prix = []
        Carburant = []
        Km = []
        Annee = []

        for item in htmlpage2.find('div', {'class': 'list-group list'}).findAll({'a'})[::2]:
            url.append("https://occasion.largus.fr" + item.get("href"))
            Model.append(item.get("data-title").split("-")[0])
            Prix.append(item.get("data-title").split("-")[1])

        for item in htmlpage2.find('div', {'class': 'list-group list'}).findAll('div', {'class': 'col-12 col-sm-9 bottom'}):
            Carburant.append(item.findAll("li")[0].text)
            Km.append(item.findAll("li")[1].text)
            Annee.append(item.findAll("li")[2].text)
        self.df = pd.DataFrame({'Model': Model, 'Prix': Prix, 'Carburant': Carburant, 'Km': Km, "Année": Annee, "url": url})

        response_ct = requests.get(lien2, headers=headers)
        htmlpage_ct = BeautifulSoup(response_ct.text, "html.parser")

        urlct = []
        Modelct = []
        Prixct = []
        Caracteristique = []

        for item in htmlpage_ct.find('div', {'class': 'resultList'}).findAll({'a'}):
            urlct.append("https://www.lacentrale.fr" + item.get("href"))
            for i in item.find('div', {'class': 'Vehiculecard_Vehiculecard_cardBody'}).findAll({'h2'}):
                Modelct.append(i.contents[0])
            for ii in item.find('div', {'class': 'Vehiculecard_Vehiculecard_characteristics'}).findAll({'div'}):
                Caracteristique.append(ii.text)
            for iii in item.find('div', {'class': 'Text_Text_text Vehiculecard_Vehiculecard_priceContainer Text_Text_body3'}).find({'span'}):
                Prixct.append(iii + " €")

        Prixct = Prixct[::3]
        Anneect = Caracteristique[::4]
        Kmct = Caracteristique[1::4]
        Carburantct = Caracteristique[3::4]

        self.df_ct = pd.DataFrame({'Model': Modelct, 'Prix': Prixct, 'Carburant': Carburantct, 'Km': Kmct, "Année": Anneect, "url": urlct})

        try:
            self.df2 = pd.read_csv('auto.csv')
            self.df2 = pd.concat([self.df_ct, self.df, self.df2], ignore_index=True)
            self.df2.to_csv('auto.csv', index=False)
        except:
            self.df2 = pd.concat([self.df_ct, self.df], ignore_index=True)
            self.df2.to_csv('auto.csv', index=False)

        self.new_window()

    def new_window(self):
        st.session_state.selected_item = None

        st.success("Les annonces sont à jour.")
        st.balloons()

        st.title("Annonces")
        st.button("Ouvrir l'annonce", on_click=self.imprimer_ligne_selectionnee)

        st.dataframe(self.df2)

if __name__ == "__main__":
    MonApp()